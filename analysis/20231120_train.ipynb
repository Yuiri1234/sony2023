{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/env39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../src\")\n",
    "from configs.config import CONF  # noqa: E402\n",
    "from dataset.all import CustomDataset, DetectionDataset  # noqa: E402\n",
    "from model.all import (  # noqa: E402\n",
    "    CNNModel,\n",
    "    CustomFasterRCNN1,\n",
    "    CustomFasterRCNN2,\n",
    "    CustomResNetModel,\n",
    "    CustomViTModel,\n",
    "    CustomMobileNetV2Model\n",
    ")\n",
    "\n",
    "from utils import seed_worker, fix_seed  # noqa: E402\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Ref) https://cocodrips.hateblo.jp/entry/2020/05/04/210156\n",
    "\n",
    "def add_bboxes_to_image(ax, image: np.ndarray,\n",
    "                        bboxes: List[Tuple[int, int, int, int]],\n",
    "                        labels: List[str] = None,\n",
    "                        label_size: int = 10,\n",
    "                        line_width: int = 2,\n",
    "                        border_color=(0, 1, 0, 1)) -> None:\n",
    "    \"\"\"\n",
    "    Add bbox to ax\n",
    "\n",
    "    :param image: dtype=np.uint8\n",
    "    :param bbox: [(left, top, right, bottom)]\n",
    "    :param label: List[str] or None\n",
    "    :return: ax\n",
    "    \"\"\"\n",
    "    # Display the image\n",
    "    ax.imshow(image, cmap='gray')\n",
    "\n",
    "    if labels is None:\n",
    "        labels = [None] * len(bboxes)\n",
    "\n",
    "    for bbox, label in zip(bboxes, labels):\n",
    "        # Add bounding box\n",
    "        top, left, bottom, right = bbox\n",
    "        rect = patches.Rectangle((left, top), right - left, bottom - top,\n",
    "                                 linewidth=line_width,\n",
    "                                 edgecolor=border_color,\n",
    "                                 facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # label\n",
    "        if label:\n",
    "            bbox_props = dict(boxstyle=\"square,pad=0\",\n",
    "                              linewidth=line_width, facecolor=border_color,\n",
    "                              edgecolor=border_color)\n",
    "            ax.text(left, top, label,\n",
    "                    ha=\"left\", va=\"bottom\", rotation=0,\n",
    "                    size=label_size, bbox=bbox_props)\n",
    "    return ax\n",
    "\n",
    "def show(X_data, y_data, data_dicts_df):\n",
    "    fig, axes = plt.subplots(3, 10, figsize=(15, 4.5))\n",
    "    for i in range(3):\n",
    "        for j in range(10):\n",
    "            index = i*10+j\n",
    "            data = X_data[index]\n",
    "            label = y_data[index]\n",
    "            data_dict = data_dicts_df.iloc[index]\n",
    "            add_bboxes_to_image(axes[i,j], data, data_dict[\"boxes\"], data_dict[\"labels\"])\n",
    "            axes[i,j].set_title(f\"ID: {data_dict['image_id']}, Label: {label}\", fontsize=6)\n",
    "            axes[i,j].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'hidden': 512, \n",
    "    'dropout': 0.5, \n",
    "    'no_decay': ['bias', 'LayerNorm.weight'], \n",
    "    'weight_decay': 0.01, \n",
    "    'eps': '1e-10', \n",
    "    'lr': 0.002, \n",
    "    'batch_size': 8, \n",
    "    'epochs': 5, \n",
    "    'data_dir': 'all+comp', \n",
    "    'detection': True, \n",
    "    # 'model': 'fasterrcnn1',\n",
    "    'model': 'fasterrcnn2', \n",
    "    'model_layer': 18, \n",
    "    'pretrained': True, \n",
    "    # 'config': '../configs/comp_det_resnet_18.yaml', \n",
    "    'config': '../configs/comp_det_resnet_50_2.yaml',\n",
    "    'seed': 42, \n",
    "    'gpu': '0', \n",
    "    'now_str': '20231120_000000',\n",
    "    'folder': 'comp_det_resnet_18'\n",
    "}\n",
    "args = EasyDict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, cfg, generator):\n",
    "        self.cfg = cfg\n",
    "\n",
    "        # GPU設定\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = \"cuda:0\"\n",
    "        elif torch.backends.mps.is_available():\n",
    "            self.device = \"mps\"\n",
    "        else:\n",
    "            self.device = \"cpu\"\n",
    "        # self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(self.device)\n",
    "\n",
    "        # データセットの読み込み\n",
    "        X_train = np.load(\n",
    "            os.path.join(CONF.PATH.DATASET, cfg.data_dir, \"X_train_filtered.npy\")\n",
    "        )\n",
    "        y_train = np.load(\n",
    "            os.path.join(CONF.PATH.DATASET, cfg.data_dir, \"y_train_filtered.npy\")\n",
    "        )\n",
    "        X_val = np.load(\n",
    "            os.path.join(CONF.PATH.DATASET, cfg.data_dir, \"X_val_filtered.npy\")\n",
    "        )\n",
    "        y_val = np.load(\n",
    "            os.path.join(CONF.PATH.DATASET, cfg.data_dir, \"y_val_filtered.npy\")\n",
    "        )\n",
    "        print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n",
    "\n",
    "        if not cfg.detection:\n",
    "            self.train_dataset = CustomDataset(X_train, y_train)\n",
    "            self.val_dataset = CustomDataset(X_val, y_val)\n",
    "        else:\n",
    "            train_df = pd.read_json(\n",
    "                os.path.join(CONF.PATH.DATASET, cfg.data_dir, \"train.json\")\n",
    "            ).reset_index(drop=True)\n",
    "            val_df = pd.read_json(\n",
    "                os.path.join(CONF.PATH.DATASET, cfg.data_dir, \"val.json\")\n",
    "            ).reset_index(drop=True)\n",
    "            print(train_df.shape, val_df.shape)\n",
    "\n",
    "            self.train_dataset = DetectionDataset(X_train, y_train, train_df)\n",
    "            self.val_dataset = DetectionDataset(X_val, y_val, val_df)\n",
    "\n",
    "        self.train_loader = torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=cfg.batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=True,\n",
    "            pin_memory=True,  # メモリのページングをしないように設定\n",
    "            worker_init_fn=seed_worker,  # シード固定\n",
    "            generator=generator,  # シード固定\n",
    "        )\n",
    "        self.val_loader = torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=1,\n",
    "            pin_memory=True,\n",
    "            worker_init_fn=seed_worker,\n",
    "            generator=generator,\n",
    "        )\n",
    "\n",
    "        # モデルの読み込み\n",
    "        if not cfg.detection:\n",
    "            if cfg.model == \"cnn\":\n",
    "                self.model = CNNModel()\n",
    "            elif cfg.model == \"vit\":\n",
    "                # self.model = CustomViTModel(\n",
    "                #     dim=cfg.dim,\n",
    "                #     seq_len=cfg.seq_len, # 50: 7x7 patches + 1 cls-token\n",
    "                #     depth=cfg.depth,\n",
    "                #     heads=cfg.heads,\n",
    "                #     k=cfg.k,\n",
    "                #     image_size=cfg.image_size,\n",
    "                #     patch_size=cfg.patch_size,\n",
    "                #     num_classes=cfg.num_classes\n",
    "                # )\n",
    "                self.model = CustomViTModel()\n",
    "            elif cfg.model == \"resnet\":\n",
    "                self.model = CustomResNetModel(\n",
    "                    model=cfg.model_layer, pretrained=cfg.pretrained\n",
    "                )\n",
    "            elif cfg.model == \"mobilenetv2\":\n",
    "                self.model = CustomMobileNetV2Model()\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "        else:\n",
    "            if cfg.model == \"fasterrcnn1\":\n",
    "                self.model = CustomFasterRCNN1(\n",
    "                    model=cfg.model_layer, pretrained=cfg.pretrained\n",
    "                )\n",
    "            elif cfg.model == \"fasterrcnn2\":\n",
    "                self.model = CustomFasterRCNN2(\n",
    "                    pretrained=cfg.pretrained\n",
    "                )\n",
    "            # self.model = CustomFasterRCNN()\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        optimizer_grouped_parameters = [\n",
    "            # weight_decayの設定\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p\n",
    "                    for n, p in self.model.named_parameters()\n",
    "                    if not any(nd in n for nd in cfg.no_decay) and p.requires_grad\n",
    "                ],\n",
    "                \"weight_decay\": cfg.weight_decay,\n",
    "            },\n",
    "            # weight_decayを設定しない場合\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p\n",
    "                    for n, p in self.model.named_parameters()\n",
    "                    if any(nd in n for nd in cfg.no_decay) and p.requires_grad\n",
    "                ],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            optimizer_grouped_parameters, lr=float(cfg.lr), eps=float(cfg.eps)\n",
    "        )\n",
    "\n",
    "        self.log_data = []\n",
    "        self.folder = os.path.join(\n",
    "            CONF.PATH.OUTPUT, f\"{self.cfg.now_str}_{self.cfg.folder}\"\n",
    "        )\n",
    "        self.csv_file = os.path.join(self.folder, \"history.csv\")\n",
    "        self.yaml_file = os.path.join(self.folder, \"config.yaml\")\n",
    "        self.pickle_file = os.path.join(self.folder, \"config.pkl\")\n",
    "\n",
    "        # フォルダがなければ作成\n",
    "        if not os.path.exists(self.folder):\n",
    "            os.makedirs(self.folder)\n",
    "\n",
    "        # 既存のcsvファイルを空にする\n",
    "        with open(self.csv_file, \"w\", newline=\"\") as f:\n",
    "            f.truncate(0)\n",
    "\n",
    "        # EasyDictをYAMLファイルに保存\n",
    "        with open(self.yaml_file, \"w\") as yaml_file:\n",
    "            yaml.dump(self.cfg, yaml_file, default_flow_style=False)\n",
    "\n",
    "        # EasyDictをpickleファイルに保存\n",
    "        with open(self.pickle_file, \"wb\") as pickle_file:\n",
    "            pickle.dump(self.cfg, pickle_file)\n",
    "\n",
    "    def train_one_epoch(self, epoch=0):\n",
    "        \"\"\"\n",
    "        Trains the model for one epoch.\n",
    "        Config setting:\n",
    "            None\n",
    "        Inputs:\n",
    "            current epoch num\n",
    "        Returns:\n",
    "            None\n",
    "        Ourputs:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        if self.cfg.detection:\n",
    "            for i, batch in enumerate(self.train_loader):\n",
    "                global_step = i + epoch * len(self.train_loader)\n",
    "                images, answers, image_ids, boxes, labels, areas, iscrowds = batch\n",
    "                images = images.to(self.device)\n",
    "                rate = 224 / images.shape[2]\n",
    "                boxes = boxes * rate\n",
    "                areas = areas * rate * rate\n",
    "                targets = []\n",
    "                for box, label, image_id, area, iscrowd in zip(boxes, labels, image_ids, areas, iscrowds):\n",
    "                    num_box = len(iscrowd[iscrowd == 0])\n",
    "                    targets.append(\n",
    "                        {\n",
    "                            \"boxes\": box[:num_box].to(self.device),\n",
    "                            \"labels\": label[:num_box].to(self.device),\n",
    "                            \"image_id\": image_id.to(self.device),\n",
    "                            \"area\": area[:num_box].to(self.device),\n",
    "                            \"iscrowd\": iscrowd[:num_box].to(self.device),\n",
    "                        }\n",
    "                    )\n",
    "                # print(images.shape, targets)\n",
    "                loss_dict = self.model(images, targets)\n",
    "\n",
    "                losses = 0\n",
    "                for k, v in loss_dict.items():\n",
    "                    if k == \"loss_objectness\" or k == \"loss_rpn_box_reg\":\n",
    "                        losses += 10 * v\n",
    "                    else:\n",
    "                        losses += v\n",
    "                # losses = sum(loss for loss in loss_dict.values())\n",
    "                loss_value = losses.item()\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                losses.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                if global_step % 100 == 0:\n",
    "                    log = {\n",
    "                        \"epoch\": epoch,\n",
    "                        \"global_step\": global_step,\n",
    "                        \"loss\": loss_value,\n",
    "                    }\n",
    "                    log.update({k: v.item() for k, v in loss_dict.items()})\n",
    "                    print(log)\n",
    "                    self.log_data.append(log)\n",
    "                    self.write_log_to_csv()\n",
    "                # if global_step % 10 == 0:\n",
    "                    self.show_result(images, targets)\n",
    "        else:\n",
    "            for i, (X, y) in enumerate(self.train_loader):\n",
    "                global_step = i + epoch * len(self.train_loader)\n",
    "                X = X.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "\n",
    "                output = self.model(X, y)\n",
    "                loss = output[\"loss\"]\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                if global_step % 100 == 0:\n",
    "                    log = {\n",
    "                        \"epoch\": epoch,\n",
    "                        \"global_step\": global_step,\n",
    "                        \"loss\": loss.item(),\n",
    "                    }\n",
    "                    print(log)\n",
    "                    self.log_data.append(log)\n",
    "                    self.write_log_to_csv()\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Trains the model for a specified number of epochs.\n",
    "        Config setting:\n",
    "            epochs\n",
    "        Inputs:\n",
    "            None\n",
    "        Returns:\n",
    "            None\n",
    "        Ourputs:\n",
    "            trained model\n",
    "        \"\"\"\n",
    "        for epoch in tqdm(range(self.cfg.epochs)):\n",
    "            self.train_one_epoch(epoch)\n",
    "            if self.cfg.detection:\n",
    "                self.save_model(f\"epoch{epoch + 1:04d}\")\n",
    "            else:\n",
    "                if (epoch + 1) % 5 == 0:\n",
    "                    self.save_model(f\"epoch{epoch + 1:04d}\")\n",
    "\n",
    "        self.save_model(\"model\")\n",
    "\n",
    "    def save_model(self, name):\n",
    "        torch.save(self.model.state_dict(), os.path.join(self.folder, f\"{name}.pth\"))\n",
    "\n",
    "    def write_log_to_csv(self):\n",
    "        with open(self.csv_file, \"a\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=self.log_data[0].keys())\n",
    "\n",
    "            if f.tell() == 0:\n",
    "                writer.writeheader()\n",
    "\n",
    "            writer.writerow(self.log_data[-1])\n",
    "\n",
    "    def show_result(self, images, targets):\n",
    "        rate =  20 / 224\n",
    "        self.model.eval()\n",
    "        fig, axes = plt.subplots(2, images.shape[0], figsize=(images.shape[0], 2))\n",
    "        for i in range(images.shape[0]):\n",
    "            image = images[i].cpu()\n",
    "            target = targets[i]\n",
    "            boxes = target[\"boxes\"].cpu().numpy()\n",
    "            labels = target[\"labels\"].cpu().numpy()\n",
    "            add_bboxes_to_image(axes[0,i], image, boxes * rate, labels)\n",
    "            axes[0,i].axis('off')\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(images)\n",
    "        for i, output in enumerate(outputs):\n",
    "            image = images[i].cpu()\n",
    "            boxes = output[\"boxes\"].cpu().numpy()\n",
    "            labels = output[\"labels\"].cpu().numpy()\n",
    "            scores = output[\"scores\"].cpu().numpy()\n",
    "            if len(scores) == 0:\n",
    "                threshold = 0\n",
    "            elif len(scores) < 3:\n",
    "                threshold = scores.min()\n",
    "            else:\n",
    "                threshold = sorted(scores)[-3]\n",
    "            boxes = boxes[scores > threshold]\n",
    "            labels = labels[scores > threshold]\n",
    "            add_bboxes_to_image(axes[1,i], image, boxes * rate, labels)\n",
    "            axes[1,i].axis('off')\n",
    "        plt.title(f\"Step: {self.log_data[-1]['global_step']}\")\n",
    "        self.model.train()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "(192000, 400) (192000,) (48000, 400) (48000,)\n",
      "(192000, 5) (48000, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacty of 7.78 GiB of which 206.75 MiB is free. Process 3084 has 155.06 MiB memory in use. Including non-PyTorch memory, this process has 7.00 GiB memory in use. Of the allocated memory 6.65 GiB is allocated by PyTorch, and 129.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb セル 5\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m cfg\u001b[39m.\u001b[39mupdate(args)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(cfg, generator\u001b[39m=\u001b[39mg)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "\u001b[1;32m/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb セル 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb#W5sZmlsZQ%3D%3D?line=230'>231</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb#W5sZmlsZQ%3D%3D?line=231'>232</a>\u001b[0m \u001b[39mTrains the model for a specified number of epochs.\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb#W5sZmlsZQ%3D%3D?line=232'>233</a>\u001b[0m \u001b[39mConfig setting:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb#W5sZmlsZQ%3D%3D?line=239'>240</a>\u001b[0m \u001b[39m    trained model\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb#W5sZmlsZQ%3D%3D?line=240'>241</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb#W5sZmlsZQ%3D%3D?line=241'>242</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mepochs)):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb#W5sZmlsZQ%3D%3D?line=242'>243</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_one_epoch(epoch)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb#W5sZmlsZQ%3D%3D?line=243'>244</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mdetection:\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb#W5sZmlsZQ%3D%3D?line=244'>245</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_model(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m04d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb セル 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb#W5sZmlsZQ%3D%3D?line=169'>170</a>\u001b[0m     targets\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb#W5sZmlsZQ%3D%3D?line=170'>171</a>\u001b[0m         {\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb#W5sZmlsZQ%3D%3D?line=171'>172</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mboxes\u001b[39m\u001b[39m\"\u001b[39m: box[:num_box]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb#W5sZmlsZQ%3D%3D?line=176'>177</a>\u001b[0m         }\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb#W5sZmlsZQ%3D%3D?line=177'>178</a>\u001b[0m     )\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb#W5sZmlsZQ%3D%3D?line=178'>179</a>\u001b[0m \u001b[39m# print(images.shape, targets)\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb#W5sZmlsZQ%3D%3D?line=179'>180</a>\u001b[0m loss_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(images, targets)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb#W5sZmlsZQ%3D%3D?line=181'>182</a>\u001b[0m losses \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/user/Documents/competition/sony2023/analysis/20231120_train.ipynb#W5sZmlsZQ%3D%3D?line=182'>183</a>\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m loss_dict\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/anaconda3/envs/env39/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/env39/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/competition/sony2023/analysis/../src/model/all.py:273\u001b[0m, in \u001b[0;36mCustomFasterRCNN2.forward\u001b[0;34m(self, x, targets)\u001b[0m\n\u001b[1;32m    271\u001b[0m x \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mresize(x, (\u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m), antialias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    272\u001b[0m \u001b[39mif\u001b[39;00m targets \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfrcnn(x, targets)\n\u001b[1;32m    274\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfrcnn(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/env39/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/env39/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env39/lib/python3.9/site-packages/torchvision/models/detection/generalized_rcnn.py:101\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     94\u001b[0m             degen_bb: List[\u001b[39mfloat\u001b[39m] \u001b[39m=\u001b[39m boxes[bb_idx]\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     95\u001b[0m             torch\u001b[39m.\u001b[39m_assert(\n\u001b[1;32m     96\u001b[0m                 \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     97\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mAll bounding boxes should have positive height and width.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Found invalid box \u001b[39m\u001b[39m{\u001b[39;00mdegen_bb\u001b[39m}\u001b[39;00m\u001b[39m for target at index \u001b[39m\u001b[39m{\u001b[39;00mtarget_idx\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     99\u001b[0m             )\n\u001b[0;32m--> 101\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackbone(images\u001b[39m.\u001b[39;49mtensors)\n\u001b[1;32m    102\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(features, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m    103\u001b[0m     features \u001b[39m=\u001b[39m OrderedDict([(\u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m, features)])\n",
      "File \u001b[0;32m~/anaconda3/envs/env39/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/env39/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env39/lib/python3.9/site-packages/torchvision/models/detection/backbone_utils.py:58\u001b[0m, in \u001b[0;36mBackboneWithFPN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Tensor]:\n\u001b[1;32m     57\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbody(x)\n\u001b[0;32m---> 58\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfpn(x)\n\u001b[1;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/env39/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/env39/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env39/lib/python3.9/site-packages/torchvision/ops/feature_pyramid_network.py:192\u001b[0m, in \u001b[0;36mFeaturePyramidNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    189\u001b[0m results\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_result_from_layer_blocks(last_inner, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m    191\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(x) \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m--> 192\u001b[0m     inner_lateral \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_result_from_inner_blocks(x[idx], idx)\n\u001b[1;32m    193\u001b[0m     feat_shape \u001b[39m=\u001b[39m inner_lateral\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:]\n\u001b[1;32m    194\u001b[0m     inner_top_down \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39minterpolate(last_inner, size\u001b[39m=\u001b[39mfeat_shape, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnearest\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/env39/lib/python3.9/site-packages/torchvision/ops/feature_pyramid_network.py:155\u001b[0m, in \u001b[0;36mFeaturePyramidNetwork.get_result_from_inner_blocks\u001b[0;34m(self, x, idx)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mfor\u001b[39;00m i, module \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minner_blocks):\n\u001b[1;32m    154\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m idx:\n\u001b[0;32m--> 155\u001b[0m         out \u001b[39m=\u001b[39m module(x)\n\u001b[1;32m    156\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/env39/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/env39/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env39/lib/python3.9/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/env39/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/env39/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env39/lib/python3.9/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/env39/lib/python3.9/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacty of 7.78 GiB of which 206.75 MiB is free. Process 3084 has 155.06 MiB memory in use. Including non-PyTorch memory, this process has 7.00 GiB memory in use. Of the allocated memory 6.65 GiB is allocated by PyTorch, and 129.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "g = fix_seed(args.seed)\n",
    "cfg = EasyDict(yaml.load(open(args.config), yaml.SafeLoader))\n",
    "cfg.update(args)\n",
    "\n",
    "trainer = Trainer(cfg, generator=g)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
